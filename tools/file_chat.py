"""
ãƒ•ã‚¡ã‚¤ãƒ«å¯¾è©±ãƒ„ãƒ¼ãƒ« - Streamlit UI

ä½¿ç”¨æ–¹æ³•:
    streamlit run tools/file_chat.py
"""
import os
import sys
import json
import tempfile
from pathlib import Path

import streamlit as st
from openai import OpenAI

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent))
from file_reader import read_file

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="File Chat - ãƒ•ã‚¡ã‚¤ãƒ«å¯¾è©±ãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ“„",
    layout="wide"
)

# ==================== ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ====================
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")

    # APIè¨­å®š
    api_base_url = st.text_input(
        "API Base URL",
        value=st.session_state.get("api_base_url", "http://localhost:8000/v1"),
        help="ç¤¾å†…LLM APIã®ã‚¢ãƒ‰ãƒ¬ã‚¹"
    )
    st.session_state.api_base_url = api_base_url

    model = st.selectbox(
        "ãƒ¢ãƒ‡ãƒ«",
        ["gpt-5", "gpt-5-thinking", "gpt-4.1-mini", "gpt-4o"],
        index=0
    )

    st.divider()

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    st.header("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_file = st.file_uploader(
        "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
        type=["txt", "json", "pdf", "csv", "docx", "xlsx", "md", "xml",
              "html", "log", "yaml", "yml", "py", "js", "ts", "java",
              "sql", "sh", "bat", "ini", "cfg", "toml"],
        help="TXT, JSON, PDF, CSV, DOCX, XLSX, MD, XML ç­‰ã®å½¢å¼ã«å¯¾å¿œ"
    )

    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†
    if uploaded_file is not None:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        suffix = Path(uploaded_file.name).suffix
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(uploaded_file.getvalue())
            tmp_path = tmp.name

        try:
            file_content = read_file(tmp_path)
            st.session_state.file_content = file_content
            st.session_state.file_name = uploaded_file.name
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Šå¤±æ•—: {e}")
            st.session_state.file_content = None
            st.session_state.file_name = None
        finally:
            os.unlink(tmp_path)

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    if st.session_state.get("file_content"):
        content = st.session_state.file_content
        char_count = len(content)
        st.info(f"ğŸ“„ **{st.session_state.file_name}** ({char_count:,} æ–‡å­—)")

        if char_count > 50000:
            st.warning(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤§ãã„ã§ã™ ({char_count:,} æ–‡å­—)ã€‚50,000æ–‡å­—ã‚’è¶…ãˆã‚‹å ´åˆã¯è‡ªå‹•çš„ã«ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã—ã¦é€ä¿¡ã•ã‚Œã¾ã™")

        with st.expander("ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=False):
            preview = content[:2000]
            if len(content) > 2000:
                preview += f"\n\n... (æ®‹ã‚Š {len(content) - 2000:,} æ–‡å­—)"
            st.text(preview)

    st.divider()

    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    st.header("ğŸ’¬ ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
    system_prompt = st.text_area(
        "ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (ä»»æ„)",
        value=st.session_state.get("system_prompt", ""),
        height=100,
        placeholder="ä¾‹: ã‚ãªãŸã¯ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†æã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    )
    st.session_state.system_prompt = system_prompt

    st.divider()

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
    st.header("ğŸ”— ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†")
    conv_id = st.session_state.get("conversation_id")
    if conv_id:
        st.success(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: `{conv_id}`")
    else:
        st.info("ã‚»ãƒƒã‚·ãƒ§ãƒ³æœªç¢ºç«‹")

    if st.button("ğŸ”„ æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³", use_container_width=True):
        st.session_state.conversation_id = None
        st.session_state.new_conversation = True
        st.session_state.chat_history = []
        st.rerun()


# ==================== çŠ¶æ…‹åˆæœŸåŒ– ====================
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "conversation_id" not in st.session_state:
    st.session_state.conversation_id = None
if "new_conversation" not in st.session_state:
    st.session_state.new_conversation = True
if "file_content" not in st.session_state:
    st.session_state.file_content = None
if "file_name" not in st.session_state:
    st.session_state.file_name = None

# ==================== ãƒ¡ã‚¤ãƒ³ç”»é¢ ====================
st.title("ğŸ“„ File Chat - ãƒ•ã‚¡ã‚¤ãƒ«å¯¾è©±ãƒ„ãƒ¼ãƒ«")
st.caption("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€AIã«è³ªå•ã—ã€ã‚¹ãƒãƒ¼ãƒˆãªåˆ†æã‚’å–å¾—")

# å±¥æ­´ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
user_input = st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...")

if user_input:
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰
    messages = []

    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    if st.session_state.system_prompt:
        messages.append({
            "role": "system",
            "content": st.session_state.system_prompt
        })

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã‚ã‚Šã€æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆã¾ãŸã¯æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼‰ã®å ´åˆã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å«ã‚ã‚‹
    file_content = st.session_state.get("file_content")
    is_first_message = len(st.session_state.chat_history) == 0

    if file_content and is_first_message:
        # æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å«ã‚ã‚‹
        combined = f"ä»¥ä¸‹ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{st.session_state.file_name}ã€ã®å†…å®¹ã§ã™:\n\n{file_content}\n\n---\n\n{user_input}"
        messages.append({"role": "user", "content": combined})
        display_text = user_input  # ç”»é¢ã«ã¯è³ªå•ã®ã¿è¡¨ç¤º
    else:
        messages.append({"role": "user", "content": user_input})
        display_text = user_input

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    with st.chat_message("user"):
        st.markdown(display_text)
    st.session_state.chat_history.append({"role": "user", "content": display_text})

    # APIã‚’å‘¼ã³å‡ºã—
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

        try:
            client = OpenAI(
                base_url=st.session_state.api_base_url,
                api_key="not-needed"
            )

            # è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
            extra_body = {}
            if st.session_state.get("new_conversation"):
                extra_body["new_conversation"] = True
                st.session_state.new_conversation = False
            elif st.session_state.get("conversation_id"):
                extra_body["conversation_id"] = st.session_state.conversation_id

            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            stream = client.chat.completions.create(
                model=model,
                messages=messages,
                stream=True,
                extra_body=extra_body if extra_body else None
            )

            for chunk in stream:
                # conversation_idã‚’æŠ½å‡ºï¼ˆã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰ï¼‰
                if hasattr(chunk, "conversation_id") and chunk.conversation_id:
                    st.session_state.conversation_id = chunk.conversation_id
                # raw dataå†…ã®conversation_idã‚‚ç¢ºèª
                if hasattr(chunk, "model_extra") and chunk.model_extra:
                    conv_id_from_extra = chunk.model_extra.get("conversation_id")
                    if conv_id_from_extra:
                        st.session_state.conversation_id = conv_id_from_extra

                if chunk.choices and chunk.choices[0].delta.content:
                    full_response += chunk.choices[0].delta.content
                    message_placeholder.markdown(full_response + "â–Œ")

            message_placeholder.markdown(full_response)

        except Exception as e:
            error_msg = f"APIå‘¼ã³å‡ºã—å¤±æ•—: {e}"
            message_placeholder.error(error_msg)
            full_response = error_msg

        st.session_state.chat_history.append({"role": "assistant", "content": full_response})

    st.rerun()
